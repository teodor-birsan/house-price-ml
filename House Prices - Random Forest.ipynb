{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f797fb1c",
   "metadata": {},
   "source": [
    "# House Prices - Random Forest\n",
    "For this problem I made a random forest with an optimal number of trees to avoid overfitting and underfitting. To achieve this I made a list with several numbers of trees, created a model for each amount of trees, calculated MAE for each model and chose the model with the lowest MAE.\n",
    "\n",
    "## Implementation\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8971d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8ac60",
   "metadata": {},
   "source": [
    "### Features and prediction target\n",
    "These are the house features that the model will learn from and use to predict house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60420d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSE_FEATURES = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', '1stFlrSF', \n",
    "                  '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n",
    "                  'TotRmsAbvGrd', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \n",
    "                  'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "TARGET_PREDICTION = \"SalePrice\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c81498",
   "metadata": {},
   "source": [
    "### Load data function\n",
    "This function will load data from a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1e2b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.load_data(path: str, describe: bool = False) -> pandas.core.frame.DataFrame>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(path: str, describe: bool = False) -> DataFrame:\n",
    "    \"\"\"Loads a dataset from a csv file.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the csv file.\n",
    "        describe (bool, optional): Boolean value used to choose whether to print or not the description of the dataset. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: the dataset from the csv file\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(path)\n",
    "    if describe:\n",
    "        print(\"Dataset details: \\n\", dataset.describe())\n",
    "    return dataset\n",
    "load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9d712",
   "metadata": {},
   "source": [
    "### Create model function\n",
    "This function will create a random forest model with a given number of trees and will return the model and its mae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcf0c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.random_forest(train_dataset: pandas.core.frame.DataFrame, test_size: float = 0.3, nodes: int = 100, save: bool = False) -> tuple[sklearn.ensemble._forest.RandomForestRegressor, float]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_forest(train_dataset: DataFrame, test_size: float = 0.3, nodes: int = 100, save: bool = False) -> tuple[RandomForestRegressor, float]:\n",
    "    \"\"\"This function splits the train_dataset into two subsets: one is used for fitting and the other for validation.\n",
    "    Then it creates the model, trains it with the fitting data, makes prediction using validation data then calculates mae.\n",
    "\n",
    "    Args:\n",
    "        train_dataset (DataFrame): The data that will be used for training and validation.\n",
    "        test_size (float, optional): The amount of data that will be used as validation data. Defaults to 0.3.\n",
    "        nodes (int, optional): The number of trees in the forest. Defaults to 100.\n",
    "        save (bool, optional): A value that indicates whether or not the model will be saved as a .pkl file. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple[RandomForestRegressor, float]: A tuple that contains the model and its MAE.\n",
    "    \"\"\"\n",
    "    X = train_dataset[HOUSE_FEATURES]\n",
    "    y = train_dataset[TARGET_PREDICTION]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=test_size)\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        random_state=1,\n",
    "        n_estimators=nodes\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    if save:\n",
    "        with open(f\"models/random_forrest_n{nodes}.pkl\", 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    return (model, mae)\n",
    "\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a0256f",
   "metadata": {},
   "source": [
    "### Best random forest\n",
    "This function will return the most optimal random forest, thus avoiding overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444dda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_random_forest(train_dataset: DataFrame, validation_data: DataFrame, \n",
    "                       nodes_list: list[int],  test_size: float = 0.3, \n",
    "                       save: bool = False)-> tuple[RandomForestRegressor, ndarray, float, int]:\n",
    "    \"\"\"This function iterates through a list of number of trees and creates and fits model and calculate their mae for \n",
    "    each number of trees. The function return only the model wiht the lowest mae.\n",
    "\n",
    "    Args:\n",
    "        train_dataset (DataFrame): Data used for fitting.\n",
    "        validation_data (DataFrame): New data used for predictions.\n",
    "        nodes_list (list[int]): A list with numbers of trees.\n",
    "        test_size (float, optional): The amount of training data that will be used for validation. Defaults to 0.3.\n",
    "        save (bool, optional): A value that indicates whether or not the model will be saved as a .pkl file. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple[RandomForestRegressor, ndarray, float, int]: The best model, the predictions from new data, mae and the number of trees.\n",
    "    \"\"\"\n",
    "    best_nodes = nodes_list[0]\n",
    "    best_model, min_mae = random_forest(train_dataset, nodes=nodes_list[0], test_size=test_size)\n",
    "    for nodes in nodes_list:\n",
    "        model, mae = random_forest(train_dataset=train_dataset, nodes=nodes, test_size=test_size)\n",
    "        if mae < min_mae:\n",
    "            best_nodes = nodes\n",
    "            min_mae = mae\n",
    "            best_model = model\n",
    "    if save:\n",
    "        with open(f\"models/random_forrest_n{best_nodes}.pkl\", 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "    X_val = validation_data[HOUSE_FEATURES]\n",
    "    predictions = best_model.predict(X_val)\n",
    "    return (best_model, predictions, min_mae, best_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460ceaf",
   "metadata": {},
   "source": [
    "### Finding and training the best model for the house prices problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ddfd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees: 3000\n",
      "\n",
      "MAE: 18934.660216496344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodes_list = [50, 500, 1000, 2000, 3000, 5000] # The list with the number of trees for each model\n",
    "train_dataset = load_data(\"dataset\\\\train.csv\")\n",
    "test_dataset = load_data(\"dataset\\\\test.csv\")\n",
    "model, prediction, mae, nodes = best_random_forest(\n",
    "    train_dataset=train_dataset,\n",
    "    validation_data=test_dataset, \n",
    "    nodes_list=nodes_list, \n",
    "    save=True) # the best model will be saved as a .pkl file\n",
    "\n",
    "print(f\"Number of trees: {nodes}\\n\")\n",
    "print(f\"MAE: {mae}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81456c9c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
